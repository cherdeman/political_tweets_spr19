{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from db_client import DBClient\n",
    "from analysis.data_clean import DataClean\n",
    "import pandas as pd\n",
    "import ast\n",
    "from nltk.util import ngrams\n",
    "from gensim import corpora, models\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_word_counts(bow_corpus):\n",
    "    counts = {}\n",
    "    for bow in bow_corpus:\n",
    "        for word in bow:\n",
    "            if word[0] not in counts.keys():\n",
    "                counts[word[0]] = 0\n",
    "            counts[word[0]] += word[1]\n",
    "    return [(k, counts[k]) for k in sorted(counts, key=counts.get, reverse=True)]\n",
    "\n",
    "def print_word_counts(word_counts, num_words, word_dict):\n",
    "    for tup in word_counts[0:num_words]:\n",
    "        print(f\"{word_dict[tup[0]]}, {tup[1]} times\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to political tweets DB\n",
      "db write committed\n"
     ]
    }
   ],
   "source": [
    "# create db client and set seed\n",
    "db = DBClient()\n",
    "db.write([\"SELECT setseed(0.5)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_hash_dem = [\"#bluewave2018\", \"#bluewave18\", \"#bluewave\", \"#democrats\", \"#resist\", \"#resistance\", \"#voteblue\", \n",
    "\"#Votethemout\", \"#WinBlue\", \"#YesWeCan\", \"#FlipItBlue\"]\n",
    "\n",
    "select_hash_rep = [\"#trump\", \"#maga\", \"#gop\", \"#republican\", \"#trumptrain\", \"#kag\", \"#LeadRight\", \"#VoteRed\", \n",
    "\"#RedWave\", \"#VoteDemsOut\"]\n",
    "\n",
    "select_hash = select_hash_dem + select_hash_rep\n",
    "dc = DataClean(select_hash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_query = \"\"\"\n",
    "with random_tweets as (\n",
    "    select tweet_text_clean, Random() from staging.{}\n",
    "    where tweet_date between '2018-01-01' and '2019-01-01'\n",
    "    order by Random()\n",
    "    limit 50000)\n",
    "select tweet_text_clean \n",
    "from random_tweets;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "for table in [\"democrat\", \"republican\", \"house\", \"senate\"]:\n",
    "    tweets = pd.DataFrame(db.read(data_query.format(table)))\n",
    "    docs = docs + [ast.literal_eval(doc) for doc in tweets[0].tolist()]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@knoone413',\n",
       " '@superstimpy',\n",
       " '@nbcolympics',\n",
       " 'insult',\n",
       " '#socialism',\n",
       " '#feelthebern',\n",
       " 'folk',\n",
       " 'know',\n",
       " 'ask',\n",
       " 'also',\n",
       " '#imwithher',\n",
       " '#democrats',\n",
       " 'also',\n",
       " 'pull',\n",
       " '#fakenews',\n",
       " 'especially',\n",
       " '@cnn',\n",
       " '@nytimes',\n",
       " '#maga',\n",
       " '#trumptrain']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bigrams(tweet):\n",
    "    return [\"_\".join(w) for w in ngrams(tweet, 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alenastern/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: generator 'ngrams' raised StopIteration\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "bigrams = list(map(bigrams, docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = [tweet for tweet in bigrams if len(tweet) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@lindasuhler_im',\n",
       " 'im_perma',\n",
       " 'perma_#shadowbanned',\n",
       " '#shadowbanned_#retweet',\n",
       " '#retweet_would',\n",
       " 'would_heres',\n",
       " 'heres_true',\n",
       " 'true_story',\n",
       " 'story_#gentleman',\n",
       " '#gentleman_#democrats',\n",
       " '#democrats_#progressives',\n",
       " '#progressives_#metoo',\n",
       " '#metoo_#timesup',\n",
       " '#timesup_#womensmarch2018',\n",
       " '#womensmarch2018_#trumprussia',\n",
       " '#trumprussia_#trumprussiaconspiracy',\n",
       " '#trumprussiaconspiracy_#trumprussiacoverup',\n",
       " '#trumprussiacoverup_#trumpcolluded',\n",
       " '#trumpcolluded_video']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams_clean = list(map(lambda x: [bigram for bigram in x if (not bigram.startswith(\"#\")) and (not bigram.startswith(\"@\"))\n",
    "                        and (\"_#\" not in bigram) and (\"_@\" not in bigram)], bigrams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams_clean = [tweet for tweet in bigrams_clean if len(tweet) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "president_trump, 1977 times\n",
      "health_care, 1842 times\n",
      "make_sure, 1759 times\n",
      "look_forward, 1390 times\n",
      "donald_trump, 1072 times\n",
      "united_state, 1068 times\n",
      "tax_cut, 1034 times\n",
      "last_night, 945 times\n",
      "every_day, 940 times\n",
      "trump_administration, 931 times\n",
      "white_house, 926 times\n",
      "supreme_court, 905 times\n",
      "follow_back, 898 times\n",
      "im_proud, 897 times\n",
      "american_people, 891 times\n",
      "get_vote, 882 times\n",
      "election_day, 808 times\n",
      "look_like, 802 times\n",
      "town_hall, 790 times\n",
      "year_ago, 749 times\n",
      "gun_violence, 693 times\n",
      "work_hard, 682 times\n",
      "social_security, 669 times\n",
      "small_business, 660 times\n",
      "preexist_condition, 651 times\n",
      "law_enforcement, 644 times\n",
      "open_letter, 640 times\n",
      "knock_door, 637 times\n",
      "hard_work, 615 times\n",
      "work_together, 579 times\n",
      "god_bless, 560 times\n",
      "early_voting, 550 times\n",
      "men_woman, 542 times\n",
      "climate_change, 534 times\n",
      "register_vote, 522 times\n",
      "need_help, 515 times\n",
      "last_year, 510 times\n",
      "high_school, 498 times\n",
      "cant_wait, 484 times\n",
      "last_week, 482 times\n",
      "great_time, 480 times\n",
      "make_america, 461 times\n",
      "across_country, 460 times\n",
      "take_back, 454 times\n",
      "national_security, 454 times\n",
      "let_get, 435 times\n",
      "special_interest, 429 times\n",
      "new_jersey, 422 times\n",
      "dont_want, 419 times\n",
      "new_york, 413 times\n"
     ]
    }
   ],
   "source": [
    "bigram_dict = corpora.Dictionary(bigrams_clean)\n",
    "bigram_bow_corpus = [bigram_dict.doc2bow(doc) for doc in bigrams_clean]\n",
    "bigram_counts = get_word_counts(bigram_bow_corpus)\n",
    "print_word_counts(bigram_counts, 50, bigram_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count_to_csv(word_counts, num_words, word_dict):\n",
    "    with open('topic_bigrams.csv','w') as f:\n",
    "        writer = csv.writer(f, delimiter= ',')\n",
    "        for tup in word_counts[0:num_words]:\n",
    "            writer.writerow([word_dict[tup[0]], tup[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count_to_csv(bigram_counts, 1000, bigram_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
