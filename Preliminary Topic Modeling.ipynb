{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary \"Base\" Topic Modeling\n",
    "Citation:\n",
    "https://towardsdatascience.com/topic-modeling-and-latent-dirichlet-allocation-in-python-9bf156893c24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from src.db_client import DBClient\n",
    "import pandas as pd\n",
    "from gensim import corpora, models\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to political tweets DB\n"
     ]
    }
   ],
   "source": [
    "db = DBClient(secrets_path = \"configs/db_secrets.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_query = \"\"\"\n",
    "with random_tweets as (\n",
    "    select tweet_text_clean, Random() from staging.{}\n",
    "    where tweet_date between '2018-01-01' and '2019-01-01'\n",
    "    order by Random()\n",
    "    limit 10000)\n",
    "select tweet_text_clean \n",
    "from random_tweets;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tax_query = \"\"\"\n",
    "select tweet_text_clean from staging.{}\n",
    "where tweet_date between '2018-01-01' and '2019-01-01'\n",
    "and tweet_text_clean like '%health%'\n",
    "limit 10000  \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_word_counts(bow_corpus):\n",
    "    counts = {}\n",
    "    for bow in bow_corpus:\n",
    "        for word in bow:\n",
    "            if word[0] not in counts.keys():\n",
    "                counts[word[0]] = 0\n",
    "            counts[word[0]] += word[1]\n",
    "    return [(k, counts[k]) for k in sorted(counts, key=counts.get, reverse=True)]\n",
    "\n",
    "def print_word_counts(word_counts, num_words, word_dict):\n",
    "    for tup in word_counts[0:num_words]:\n",
    "        print(f\"{word_dict[tup[0]]}, {tup[1]} times\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Democrats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dem_tax_tweets = pd.DataFrame(db.read(tax_query.format(\"democrat\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['omg', '#barbaric', 'amp', '#fiendish', '#cor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['@housedemocrats', '@gop', 'go', 'stop', 'pot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['@tedlieu', '@speakerryan', 'might', 'nice', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['#democraticagenda', 'affordable', 'healthcar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['@foxnews', '@gregabbotttx', 'stop', 'take', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>['@pelucachick46', '@tomperez', '@nancypelosi'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>['healthcare', 'immigration', 'tax', 'reform',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>['@realdonaldtrump', '@momsdemand', '@corapunz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>['@realdonaldtrump', 'hey', '#oh12', '#gotv', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>['im', 'sure', 'im', 'happy', 'result', 'study...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>['chuck', 'norris', 'approves', 'get', 'fit', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>['please', 'take', 'time', 'get', 'involved', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>['nasty', 'woman', 'earring', '#handmade', 'sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>['@cacountryman', '#rethinkalabama', '#neweraf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>['extremist', 'pick', 'scotus', 'could', 'pret...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>['@mamarose2017', '@keanothedog', '@troublingt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>['paycheck', '8181', 'month', '@gop', 'tax', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>['wake', 'call', 'think', 'vote', 'doesnt', 'm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>['rt', '#election2018', 'cd22', '#winblue', 's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>['@pajjr2016', '@bornabrit1', 'hell', 'see', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>['leave', 'another', 'evening', '@flipitblue',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>['new', '#healthcare', 'sabotage', 'trump', 'o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>['@aquilasuperbia', '@nutritionbee', '@eatheal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>['havent', 'voted', 'vote', 'danny', 'oconnor'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>['thank', 'everyone', 'march', 'calledpostcard...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>['body', 'never', 'compare', 'halfeaten', 'foo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>['mad', '@barackobama', 'didnt', 'sign', 'bill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>['big', 'thanks', '@coloradodems', 'endorsemen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>['@heyyou2486', 'hi', 'im', 'sorry', 'miss', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>['@kharyp', '#grabyourwallet', '@cvspharmacy',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>['#jeffflake', 'permanently', 'go', 'away', 'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>['florida', 'friend', 'family', 'gotv', 'yall'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>['@jamesmpope', '@cspanwj', '@mkazin', '@georg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>['thank', 'continued', 'support', 'amp', 'stro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>['resistance', 'need', 'rightwing', 'judge', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>['im', '#teampelosi', 'freshman', 'newbie', 'o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>['@markknoller', '@presssec', '@kellyannepolls...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>['#voteblue', 'say', 'yes', 'affordable', 'hea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>['worker', 'stage', '1day', 'protest', 'southe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>['yes', 'congrats', '@andykimnj', 'amp', '#nj0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>['keep', '#bluewave', 'go', 'write', '#postcar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>['@resetamer2018', '@gypsyinca', '@rosewoo1509...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>['#smartdissent', 'database', 'action', '#trum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>['add', 'name', 'dont', 'let', 'trump', 'steal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>['@cameronkgvi', '@sruhle', 'join', '#ivoted',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>['@mimiwaltersca', 'seeeing', 'smile', 'laugh'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>['@abc', 'republican', 'still', 'try', 'kill',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>['ironyhypocrisy', 'alert', 'ppl', 'crowdfundi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>['shame', 'anyone', 'tear', '#petedavidson', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>['mercury', 'emission', 'rollback', 'vengeful'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>['@wvjoe911', 'old', 'asshole', 'fl', 'worry',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>['@heaven526', '@individualone19', '#fbr', '#r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>['im', 'affordable', 'care', 'act', 'like', 'a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>['instead', 'bitch', '@nancypelosi', 'try', 'c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>['@outnumberedot', '@noellenikpour', '@realdoc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>['health', 'america', 'via', 'passle', '@axcoi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>['@gopchairwoman', '@hawleymo', '@realdonaldtr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>['vote', 'vote', 'vote', 'health', 'child', 'u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>['@gop', 'amp', '@realdonaldtrump', 'afraid', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>['#smartdissent', 'database', 'action', '#trum...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1006 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      0\n",
       "0     ['omg', '#barbaric', 'amp', '#fiendish', '#cor...\n",
       "1     ['@housedemocrats', '@gop', 'go', 'stop', 'pot...\n",
       "2     ['@tedlieu', '@speakerryan', 'might', 'nice', ...\n",
       "3     ['#democraticagenda', 'affordable', 'healthcar...\n",
       "4     ['@foxnews', '@gregabbotttx', 'stop', 'take', ...\n",
       "5     ['@pelucachick46', '@tomperez', '@nancypelosi'...\n",
       "6     ['healthcare', 'immigration', 'tax', 'reform',...\n",
       "7     ['@realdonaldtrump', '@momsdemand', '@corapunz...\n",
       "8     ['@realdonaldtrump', 'hey', '#oh12', '#gotv', ...\n",
       "9     ['im', 'sure', 'im', 'happy', 'result', 'study...\n",
       "10    ['chuck', 'norris', 'approves', 'get', 'fit', ...\n",
       "11    ['please', 'take', 'time', 'get', 'involved', ...\n",
       "12    ['nasty', 'woman', 'earring', '#handmade', 'sa...\n",
       "13    ['@cacountryman', '#rethinkalabama', '#neweraf...\n",
       "14    ['extremist', 'pick', 'scotus', 'could', 'pret...\n",
       "15    ['@mamarose2017', '@keanothedog', '@troublingt...\n",
       "16    ['paycheck', '8181', 'month', '@gop', 'tax', '...\n",
       "17    ['wake', 'call', 'think', 'vote', 'doesnt', 'm...\n",
       "18    ['rt', '#election2018', 'cd22', '#winblue', 's...\n",
       "19    ['@pajjr2016', '@bornabrit1', 'hell', 'see', '...\n",
       "20    ['leave', 'another', 'evening', '@flipitblue',...\n",
       "21    ['new', '#healthcare', 'sabotage', 'trump', 'o...\n",
       "22    ['@aquilasuperbia', '@nutritionbee', '@eatheal...\n",
       "23    ['havent', 'voted', 'vote', 'danny', 'oconnor'...\n",
       "24    ['thank', 'everyone', 'march', 'calledpostcard...\n",
       "25    ['body', 'never', 'compare', 'halfeaten', 'foo...\n",
       "26    ['mad', '@barackobama', 'didnt', 'sign', 'bill...\n",
       "27    ['big', 'thanks', '@coloradodems', 'endorsemen...\n",
       "28    ['@heyyou2486', 'hi', 'im', 'sorry', 'miss', '...\n",
       "29    ['@kharyp', '#grabyourwallet', '@cvspharmacy',...\n",
       "...                                                 ...\n",
       "976   ['#jeffflake', 'permanently', 'go', 'away', 'd...\n",
       "977   ['florida', 'friend', 'family', 'gotv', 'yall'...\n",
       "978   ['@jamesmpope', '@cspanwj', '@mkazin', '@georg...\n",
       "979   ['thank', 'continued', 'support', 'amp', 'stro...\n",
       "980   ['resistance', 'need', 'rightwing', 'judge', '...\n",
       "981   ['im', '#teampelosi', 'freshman', 'newbie', 'o...\n",
       "982   ['@markknoller', '@presssec', '@kellyannepolls...\n",
       "983   ['#voteblue', 'say', 'yes', 'affordable', 'hea...\n",
       "984   ['worker', 'stage', '1day', 'protest', 'southe...\n",
       "985   ['yes', 'congrats', '@andykimnj', 'amp', '#nj0...\n",
       "986   ['keep', '#bluewave', 'go', 'write', '#postcar...\n",
       "987   ['@resetamer2018', '@gypsyinca', '@rosewoo1509...\n",
       "988   ['#smartdissent', 'database', 'action', '#trum...\n",
       "989   ['add', 'name', 'dont', 'let', 'trump', 'steal...\n",
       "990   ['@cameronkgvi', '@sruhle', 'join', '#ivoted',...\n",
       "991   ['@mimiwaltersca', 'seeeing', 'smile', 'laugh'...\n",
       "992   ['@abc', 'republican', 'still', 'try', 'kill',...\n",
       "993   ['ironyhypocrisy', 'alert', 'ppl', 'crowdfundi...\n",
       "994   ['shame', 'anyone', 'tear', '#petedavidson', '...\n",
       "995   ['mercury', 'emission', 'rollback', 'vengeful'...\n",
       "996   ['@wvjoe911', 'old', 'asshole', 'fl', 'worry',...\n",
       "997   ['@heaven526', '@individualone19', '#fbr', '#r...\n",
       "998   ['im', 'affordable', 'care', 'act', 'like', 'a...\n",
       "999   ['instead', 'bitch', '@nancypelosi', 'try', 'c...\n",
       "1000  ['@outnumberedot', '@noellenikpour', '@realdoc...\n",
       "1001  ['health', 'america', 'via', 'passle', '@axcoi...\n",
       "1002  ['@gopchairwoman', '@hawleymo', '@realdonaldtr...\n",
       "1003  ['vote', 'vote', 'vote', 'health', 'child', 'u...\n",
       "1004  ['@gop', 'amp', '@realdonaldtrump', 'afraid', ...\n",
       "1005  ['#smartdissent', 'database', 'action', '#trum...\n",
       "\n",
       "[1006 rows x 1 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dem_tax_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dem_tweets = pd.DataFrame(db.read(tax_query.format(\"democrat\")))\n",
    "dem_docs = [ast.literal_eval(doc) for doc in  dem_tweets[0].tolist()]\n",
    "dem_dict = corpora.Dictionary(dem_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Alter no_above to filter out frequently occuring words\n",
    "dem_dict.filter_extremes(no_below=15, no_above=1, keep_n=10000)\n",
    "dem_bow_corpus = [dem_dict.doc2bow(doc) for doc in dem_docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top Word Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "healthcare, 355 times\n",
      "#voteblue, 310 times\n",
      "health, 283 times\n",
      "vote, 258 times\n",
      "amp, 256 times\n",
      "#resist, 248 times\n",
      "#healthcare, 202 times\n",
      "care, 183 times\n",
      "#bluewave, 172 times\n",
      "#democrats, 135 times\n",
      "take, 121 times\n",
      "#bluewave2018, 104 times\n",
      "right, 99 times\n",
      "need, 97 times\n",
      "get, 96 times\n",
      "#resistance, 94 times\n",
      "away, 85 times\n",
      "people, 84 times\n",
      "want, 83 times\n",
      "@realdonaldtrump, 81 times\n",
      "trump, 80 times\n",
      "like, 74 times\n",
      "dont, 73 times\n",
      "@gop, 72 times\n",
      "go, 69 times\n",
      "american, 66 times\n",
      "gop, 61 times\n",
      "#trump, 57 times\n",
      "condition, 56 times\n",
      "make, 55 times\n",
      "affordable, 54 times\n",
      "tax, 54 times\n",
      "pay, 54 times\n",
      "save, 53 times\n",
      "education, 51 times\n",
      "issue, 50 times\n",
      "#maga, 49 times\n",
      "support, 49 times\n",
      "woman, 49 times\n",
      "republican, 49 times\n",
      "#vote, 48 times\n",
      "security, 48 times\n",
      "social, 48 times\n",
      "time, 46 times\n",
      "good, 46 times\n",
      "lie, 46 times\n",
      "#gop, 43 times\n",
      "let, 43 times\n",
      "child, 43 times\n",
      "work, 42 times\n"
     ]
    }
   ],
   "source": [
    "dem_counts = get_word_counts(dem_bow_corpus)\n",
    "print_word_counts(dem_counts, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dem_tfidf = models.TfidfModel(dem_bow_corpus)\n",
    "dem_corpus_tfidf = dem_tfidf[dem_bow_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dem_lda_model = models.LdaMulticore(dem_bow_corpus, num_topics=10, id2word=dem_dict, passes=2, workers=2)\n",
    "dem_lda_model_tfidf = models.LdaMulticore(dem_corpus_tfidf, num_topics=10, id2word=dem_dict, passes=2, workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.099*\"#voteblue\" + 0.081*\"healthcare\" + 0.033*\"save\" + 0.028*\"right\" + 0.028*\"security\" + 0.027*\"vote\" + 0.027*\"medicare\" + 0.026*\"social\" + 0.020*\"republican\" + 0.020*\"want\"\n",
      "Topic: 1 \n",
      "Words: 0.066*\"health\" + 0.058*\"care\" + 0.049*\"#voteblue\" + 0.029*\"american\" + 0.025*\"healthcare\" + 0.025*\"#bluewave\" + 0.023*\"amp\" + 0.020*\"right\" + 0.020*\"need\" + 0.020*\"people\"\n",
      "Topic: 2 \n",
      "Words: 0.118*\"#resist\" + 0.062*\"#healthcare\" + 0.042*\"amp\" + 0.041*\"#resistance\" + 0.040*\"#trump\" + 0.032*\"#maga\" + 0.030*\"#health\" + 0.028*\"#democrats\" + 0.024*\"trump\" + 0.022*\"#foxnews\"\n",
      "Topic: 3 \n",
      "Words: 0.073*\"health\" + 0.038*\"care\" + 0.034*\"#voteblue\" + 0.029*\"woman\" + 0.028*\"#bluewave2018\" + 0.025*\"take\" + 0.025*\"want\" + 0.022*\"#resist\" + 0.022*\"amp\" + 0.020*\"need\"\n",
      "Topic: 4 \n",
      "Words: 0.067*\"healthcare\" + 0.051*\"#resist\" + 0.039*\"#voteblue\" + 0.032*\"gop\" + 0.027*\"vote\" + 0.025*\"amp\" + 0.024*\"must\" + 0.022*\"dont\" + 0.022*\"condition\" + 0.021*\"#bluewave2018\"\n",
      "Topic: 5 \n",
      "Words: 0.043*\"#healthcare\" + 0.033*\"amp\" + 0.027*\"#bluewave\" + 0.022*\"#democrats\" + 0.020*\"#gop\" + 0.019*\"#voteblue\" + 0.019*\"@gop\" + 0.017*\"#womensrights\" + 0.017*\"#smartdissent\" + 0.017*\"#education\"\n",
      "Topic: 6 \n",
      "Words: 0.080*\"health\" + 0.056*\"#resist\" + 0.042*\"#bluewave\" + 0.036*\"#democrats\" + 0.028*\"#healthcare\" + 0.028*\"insurance\" + 0.023*\"one\" + 0.018*\"support\" + 0.018*\"voter\" + 0.018*\"help\"\n",
      "Topic: 7 \n",
      "Words: 0.058*\"#bluewave\" + 0.043*\"#healthcare\" + 0.041*\"vote\" + 0.030*\"#democrats\" + 0.029*\"care\" + 0.029*\"amp\" + 0.027*\"health\" + 0.023*\"healthcare\" + 0.022*\"away\" + 0.022*\"people\"\n",
      "Topic: 8 \n",
      "Words: 0.091*\"healthcare\" + 0.063*\"amp\" + 0.028*\"#voteblue\" + 0.027*\"#resist\" + 0.027*\"take\" + 0.019*\"@gop\" + 0.016*\"away\" + 0.016*\"people\" + 0.015*\"vote\" + 0.014*\"go\"\n",
      "Topic: 9 \n",
      "Words: 0.146*\"vote\" + 0.039*\"health\" + 0.037*\"#voteblue\" + 0.034*\"like\" + 0.032*\"#healthcare\" + 0.028*\"healthcare\" + 0.021*\"care\" + 0.019*\"#resist\" + 0.018*\"time\" + 0.016*\"need\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in dem_lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.045*\"#voteblue2018\" + 0.039*\"#bluewave2018\" + 0.037*\"#healthcarevoter\" + 0.025*\"#democrats\" + 0.023*\"#atomicveterans\" + 0.023*\"#enewetak\" + 0.023*\"parity\" + 0.023*\"#gop\" + 0.022*\"#potus\" + 0.021*\"#healthcare\"\n",
      "Topic: 1 \n",
      "Words: 0.024*\"healthy\" + 0.024*\"healthcare\" + 0.021*\"right\" + 0.020*\"protect\" + 0.019*\"people\" + 0.019*\"#voteblue\" + 0.019*\"take\" + 0.017*\"amp\" + 0.016*\"#resist\" + 0.016*\"kill\"\n",
      "Topic: 2 \n",
      "Words: 0.041*\"#democrats\" + 0.027*\"#healthcare\" + 0.025*\"#voteblue\" + 0.025*\"healthcare\" + 0.024*\"#votebluetosaveamerica\" + 0.020*\"care\" + 0.020*\"democrat\" + 0.019*\"need\" + 0.018*\"must\" + 0.016*\"like\"\n",
      "Topic: 3 \n",
      "Words: 0.038*\"#voteblue\" + 0.030*\"healthcare\" + 0.019*\"woman\" + 0.018*\"amp\" + 0.016*\"#womenshealth\" + 0.016*\"country\" + 0.015*\"#metoo\" + 0.015*\"#flipitblue\" + 0.015*\"#resist\" + 0.015*\"issue\"\n",
      "Topic: 4 \n",
      "Words: 0.058*\"#resist\" + 0.032*\"#health\" + 0.029*\"health\" + 0.025*\"care\" + 0.024*\"#bluewave\" + 0.022*\"#healthcare\" + 0.020*\"#voteblue\" + 0.019*\"#maga\" + 0.018*\"#resistance\" + 0.018*\"gun\"\n",
      "Topic: 5 \n",
      "Words: 0.054*\"vote\" + 0.020*\"child\" + 0.020*\"#voteblue\" + 0.019*\"want\" + 0.019*\"social\" + 0.018*\"security\" + 0.017*\"healthcare\" + 0.016*\"amp\" + 0.016*\"#healthcare\" + 0.015*\"make\"\n",
      "Topic: 6 \n",
      "Words: 0.024*\"#healthcare\" + 0.023*\"preexist\" + 0.023*\"condition\" + 0.022*\"#maga\" + 0.021*\"lie\" + 0.019*\"#medicare\" + 0.019*\"use\" + 0.019*\"amp\" + 0.017*\"end\" + 0.017*\"#voteblue\"\n",
      "Topic: 7 \n",
      "Words: 0.027*\"health\" + 0.024*\"trump\" + 0.022*\"#resist\" + 0.021*\"vote\" + 0.021*\"mental\" + 0.020*\"#bluewave\" + 0.019*\"@realdonaldtrump\" + 0.019*\"amp\" + 0.019*\"healthcare\" + 0.018*\"cut\"\n",
      "Topic: 8 \n",
      "Words: 0.034*\"need\" + 0.026*\"amp\" + 0.025*\"im\" + 0.023*\"take\" + 0.021*\"away\" + 0.020*\"#resistance\" + 0.020*\"one\" + 0.020*\"dont\" + 0.018*\"try\" + 0.017*\"insurance\"\n",
      "Topic: 9 \n",
      "Words: 0.037*\"#resistance\" + 0.030*\"amp\" + 0.021*\"come\" + 0.021*\"#bluewave\" + 0.020*\"#healthcare\" + 0.018*\"#bluewave2018\" + 0.015*\"dems\" + 0.015*\"healthcare\" + 0.014*\"#economy\" + 0.014*\"#trump\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in dem_lda_model_tfidf.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Republicans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rep_tweets = pd.DataFrame(db.read(tax_query.format(\"republican\")))\n",
    "rep_docs = [ast.literal_eval(doc) for doc in  rep_tweets[0].tolist()]\n",
    "rep_dict = corpora.Dictionary(dem_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adjust no_above to filter frequently occuring words\n",
    "rep_dict.filter_extremes(no_below=15, no_above=1, keep_n=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rep_bow_corpus = [rep_dict.doc2bow(doc) for doc in rep_docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top Word Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#maga, 277 times\n",
      "health, 243 times\n",
      "#trump, 201 times\n",
      "amp, 169 times\n",
      "healthcare, 129 times\n",
      "#gop, 118 times\n",
      "#healthcare, 104 times\n",
      "care, 85 times\n",
      "@realdonaldtrump, 84 times\n",
      "trump, 68 times\n",
      "mental, 67 times\n",
      "get, 59 times\n",
      "people, 58 times\n",
      "make, 56 times\n",
      "dont, 53 times\n",
      "need, 52 times\n",
      "vote, 47 times\n",
      "want, 45 times\n",
      "tax, 45 times\n",
      "take, 44 times\n",
      "go, 42 times\n",
      "gun, 40 times\n",
      "#health, 39 times\n",
      "insurance, 38 times\n",
      "give, 37 times\n",
      "right, 36 times\n",
      "like, 36 times\n",
      "america, 35 times\n",
      "back, 34 times\n",
      "good, 34 times\n",
      "cut, 33 times\n",
      "pay, 33 times\n",
      "issue, 32 times\n",
      "say, 32 times\n",
      "would, 32 times\n",
      "@gop, 30 times\n",
      "healthy, 29 times\n",
      "american, 29 times\n",
      "child, 28 times\n",
      "one, 28 times\n",
      "let, 28 times\n",
      "please, 27 times\n",
      "know, 27 times\n",
      "work, 26 times\n",
      "country, 25 times\n",
      "talk, 24 times\n",
      "stop, 24 times\n",
      "job, 24 times\n",
      "time, 23 times\n",
      "try, 23 times\n"
     ]
    }
   ],
   "source": [
    "rep_counts = get_word_counts(rep_bow_corpus)\n",
    "print_word_counts(rep_counts, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rep_tfidf = models.TfidfModel(rep_bow_corpus)\n",
    "rep_corpus_tfidf = rep_tfidf[rep_bow_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rep_lda_model = models.LdaMulticore(rep_bow_corpus, num_topics=10, id2word=rep_dict, passes=2, workers=2)\n",
    "rep_lda_model_tfidf = models.LdaMulticore(rep_corpus_tfidf, num_topics=10, id2word=rep_dict, passes=2, workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.087*\"#trump\" + 0.077*\"health\" + 0.058*\"mental\" + 0.057*\"#maga\" + 0.049*\"amp\" + 0.035*\"#health\" + 0.033*\"gun\" + 0.031*\"talk\" + 0.022*\"trump\" + 0.019*\"well\"\n",
      "Topic: 1 \n",
      "Words: 0.111*\"health\" + 0.097*\"#maga\" + 0.033*\"make\" + 0.029*\"mental\" + 0.028*\"get\" + 0.023*\"insurance\" + 0.023*\"amp\" + 0.021*\"@realdonaldtrump\" + 0.021*\"#gop\" + 0.021*\"dont\"\n",
      "Topic: 2 \n",
      "Words: 0.187*\"#maga\" + 0.067*\"healthcare\" + 0.043*\"like\" + 0.038*\"back\" + 0.030*\"need\" + 0.030*\"@realdonaldtrump\" + 0.026*\"#healthcare\" + 0.021*\"vote\" + 0.019*\"make\" + 0.018*\"trump\"\n",
      "Topic: 3 \n",
      "Words: 0.065*\"amp\" + 0.062*\"#maga\" + 0.057*\"health\" + 0.041*\"#gop\" + 0.030*\"care\" + 0.030*\"@realdonaldtrump\" + 0.028*\"healthcare\" + 0.028*\"healthy\" + 0.021*\"tax\" + 0.019*\"give\"\n",
      "Topic: 4 \n",
      "Words: 0.079*\"amp\" + 0.062*\"#healthcare\" + 0.060*\"#trump\" + 0.033*\"#gop\" + 0.023*\"take\" + 0.023*\"#medicare\" + 0.022*\"vote\" + 0.021*\"healthcare\" + 0.018*\"#socialsecurity\" + 0.018*\"#aca\"\n",
      "Topic: 5 \n",
      "Words: 0.080*\"healthcare\" + 0.066*\"#trump\" + 0.051*\"#gop\" + 0.032*\"health\" + 0.028*\"tax\" + 0.025*\"@realdonaldtrump\" + 0.024*\"pay\" + 0.022*\"#maga\" + 0.021*\"cut\" + 0.018*\"country\"\n",
      "Topic: 6 \n",
      "Words: 0.064*\"health\" + 0.043*\"#gop\" + 0.042*\"care\" + 0.041*\"want\" + 0.035*\"amp\" + 0.031*\"#healthcare\" + 0.029*\"america\" + 0.028*\"vote\" + 0.025*\"take\" + 0.024*\"@realdonaldtrump\"\n",
      "Topic: 7 \n",
      "Words: 0.082*\"health\" + 0.074*\"#trump\" + 0.059*\"care\" + 0.049*\"#maga\" + 0.039*\"amp\" + 0.039*\"trump\" + 0.030*\"people\" + 0.028*\"right\" + 0.028*\"would\" + 0.026*\"dont\"\n",
      "Topic: 8 \n",
      "Words: 0.056*\"#trump\" + 0.055*\"#healthcare\" + 0.035*\"life\" + 0.035*\"#gop\" + 0.034*\"#potus\" + 0.031*\"#democrats\" + 0.030*\"health\" + 0.026*\"#atomicveterans\" + 0.026*\"#enewetak\" + 0.026*\"parity\"\n",
      "Topic: 9 \n",
      "Words: 0.088*\"#trump\" + 0.051*\"#healthcare\" + 0.042*\"#health\" + 0.037*\"amp\" + 0.029*\"#maga\" + 0.028*\"#education\" + 0.025*\"#gop\" + 0.025*\"make\" + 0.025*\"@gop\" + 0.024*\"#environment\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in rep_lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.102*\"#health\" + 0.036*\"#trump\" + 0.032*\"#maga\" + 0.031*\"need\" + 0.027*\"want\" + 0.026*\"people\" + 0.026*\"think\" + 0.023*\"#education\" + 0.022*\"#environment\" + 0.020*\"state\"\n",
      "Topic: 1 \n",
      "Words: 0.070*\"mental\" + 0.046*\"health\" + 0.028*\"#trump\" + 0.027*\"gun\" + 0.027*\"trump\" + 0.023*\"say\" + 0.022*\"tax\" + 0.020*\"country\" + 0.018*\"people\" + 0.018*\"care\"\n",
      "Topic: 2 \n",
      "Words: 0.044*\"#mentalhealth\" + 0.031*\"#trump\" + 0.025*\"want\" + 0.024*\"via\" + 0.024*\"health\" + 0.023*\"amp\" + 0.022*\"#obamacare\" + 0.022*\"#gop\" + 0.021*\"talk\" + 0.020*\"#healthcare\"\n",
      "Topic: 3 \n",
      "Words: 0.071*\"#maga\" + 0.057*\"#trump\" + 0.049*\"@realdonaldtrump\" + 0.048*\"back\" + 0.032*\"trump\" + 0.025*\"get\" + 0.023*\"health\" + 0.022*\"vote\" + 0.022*\"#potus\" + 0.021*\"#healthcare\"\n",
      "Topic: 4 \n",
      "Words: 0.043*\"care\" + 0.038*\"would\" + 0.037*\"thanks\" + 0.029*\"work\" + 0.028*\"healthcare\" + 0.028*\"#maga\" + 0.026*\"control\" + 0.026*\"make\" + 0.025*\"health\" + 0.023*\"people\"\n",
      "Topic: 5 \n",
      "Words: 0.049*\"#healthcare\" + 0.034*\"amp\" + 0.030*\"#trump\" + 0.027*\"lie\" + 0.023*\"healthy\" + 0.023*\"via\" + 0.023*\"make\" + 0.021*\"try\" + 0.019*\"youre\" + 0.019*\"#maga\"\n",
      "Topic: 6 \n",
      "Words: 0.031*\"good\" + 0.027*\"#health\" + 0.026*\"healthcare\" + 0.022*\"let\" + 0.022*\"america\" + 0.021*\"amp\" + 0.020*\"#maga\" + 0.019*\"health\" + 0.019*\"effect\" + 0.019*\"great\"\n",
      "Topic: 7 \n",
      "Words: 0.062*\"#maga\" + 0.037*\"healthcare\" + 0.036*\"health\" + 0.027*\"like\" + 0.024*\"insurance\" + 0.022*\"amp\" + 0.021*\"good\" + 0.020*\"know\" + 0.017*\"woman\" + 0.017*\"dont\"\n",
      "Topic: 8 \n",
      "Words: 0.039*\"child\" + 0.037*\"#gop\" + 0.030*\"#healthcare\" + 0.029*\"amp\" + 0.021*\"healthcare\" + 0.020*\"make\" + 0.020*\"take\" + 0.019*\"life\" + 0.018*\"#medicare\" + 0.017*\"real\"\n",
      "Topic: 9 \n",
      "Words: 0.038*\"one\" + 0.027*\"america\" + 0.023*\"care\" + 0.022*\"#gop\" + 0.021*\"say\" + 0.021*\"#trump\" + 0.021*\"come\" + 0.019*\"try\" + 0.018*\"health\" + 0.018*\"@realdonaldtrump\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in rep_lda_model_tfidf.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# House"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "house_tweets = pd.DataFrame(db.read(tax_query.format(\"house\")))\n",
    "house_docs = [ast.literal_eval(doc) for doc in  house_tweets[0].tolist()]\n",
    "house_dict = corpora.Dictionary(house_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "house_dict.filter_extremes(no_below=15, no_above=1, keep_n=10000)\n",
    "house_bow_corpus = [house_dict.doc2bow(doc) for doc in house_docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top Word Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save, 5470 times\n",
      "amp, 3821 times\n",
      "stop, 3043 times\n",
      "family, 2365 times\n",
      "#trump, 1363 times\n",
      "protect, 1330 times\n",
      "#vote, 1228 times\n",
      "voter, 1154 times\n",
      "healthcare, 1122 times\n",
      "#gotv, 1106 times\n",
      "#immigration, 1086 times\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "336",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-95-f45f8532ab6b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mhouse_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_word_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhouse_bow_corpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint_word_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhouse_counts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-a50365da46d0>\u001b[0m in \u001b[0;36mprint_word_counts\u001b[0;34m(word_counts, num_words)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprint_word_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_counts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_counts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnum_words\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{dem_dict[tup[0]]}, {tup[1]} times\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/gensim/corpora/dictionary.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, tokenid)\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0;31m# recompute id->word accordingly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid2token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrevdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken2id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid2token\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtokenid\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# will throw for non-existent ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 336"
     ]
    }
   ],
   "source": [
    "house_counts = get_word_counts(house_bow_corpus)\n",
    "print_word_counts(house_counts, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "house_tfidf = models.TfidfModel(house_bow_corpus)\n",
    "house_corpus_tfidf = house_tfidf[house_bow_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "house_lda_model = models.LdaMulticore(house_bow_corpus, num_topics=10, id2word=house_dict, passes=2, workers=2)\n",
    "house_lda_model_tfidf = models.LdaMulticore(house_corpus_tfidf, num_topics=10, id2word=house_dict, passes=2, workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.033*\"healthcare\" + 0.032*\"amp\" + 0.018*\"health\" + 0.017*\"woman\" + 0.013*\"people\" + 0.011*\"family\" + 0.011*\"stand\" + 0.010*\"right\" + 0.009*\"care\" + 0.009*\"insurance\"\n",
      "Topic: 1 \n",
      "Words: 0.030*\"healthcare\" + 0.021*\"health\" + 0.017*\"people\" + 0.013*\"care\" + 0.012*\"work\" + 0.011*\"get\" + 0.010*\"congress\" + 0.010*\"vote\" + 0.008*\"take\" + 0.008*\"want\"\n",
      "Topic: 2 \n",
      "Words: 0.066*\"health\" + 0.034*\"care\" + 0.014*\"need\" + 0.013*\"insurance\" + 0.011*\"affordable\" + 0.011*\"american\" + 0.009*\"healthcare\" + 0.009*\"trump\" + 0.008*\"people\" + 0.008*\"coverage\"\n",
      "Topic: 3 \n",
      "Words: 0.028*\"health\" + 0.027*\"healthcare\" + 0.019*\"care\" + 0.011*\"american\" + 0.011*\"fight\" + 0.009*\"family\" + 0.009*\"amp\" + 0.009*\"affordable\" + 0.008*\"job\" + 0.008*\"make\"\n",
      "Topic: 4 \n",
      "Words: 0.023*\"health\" + 0.020*\"amp\" + 0.020*\"care\" + 0.017*\"healthcare\" + 0.016*\"vote\" + 0.010*\"support\" + 0.010*\"access\" + 0.009*\"healthy\" + 0.009*\"take\" + 0.009*\"help\"\n",
      "Topic: 5 \n",
      "Words: 0.031*\"health\" + 0.023*\"healthcare\" + 0.017*\"right\" + 0.017*\"care\" + 0.014*\"american\" + 0.013*\"year\" + 0.012*\"need\" + 0.012*\"healthy\" + 0.010*\"work\" + 0.010*\"amp\"\n",
      "Topic: 6 \n",
      "Words: 0.032*\"health\" + 0.021*\"healthcare\" + 0.013*\"vote\" + 0.013*\"care\" + 0.012*\"make\" + 0.012*\"fight\" + 0.010*\"amp\" + 0.010*\"good\" + 0.008*\"support\" + 0.008*\"congress\"\n",
      "Topic: 7 \n",
      "Words: 0.035*\"healthcare\" + 0.030*\"health\" + 0.017*\"care\" + 0.013*\"work\" + 0.013*\"people\" + 0.012*\"access\" + 0.010*\"american\" + 0.009*\"affordable\" + 0.009*\"condition\" + 0.009*\"right\"\n",
      "Topic: 8 \n",
      "Words: 0.041*\"health\" + 0.031*\"amp\" + 0.024*\"care\" + 0.021*\"healthcare\" + 0.011*\"need\" + 0.010*\"fight\" + 0.009*\"support\" + 0.009*\"access\" + 0.008*\"affordable\" + 0.008*\"vote\"\n",
      "Topic: 9 \n",
      "Words: 0.033*\"health\" + 0.020*\"healthcare\" + 0.020*\"work\" + 0.014*\"care\" + 0.014*\"amp\" + 0.012*\"fight\" + 0.011*\"congress\" + 0.010*\"make\" + 0.009*\"need\" + 0.009*\"school\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in house_lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.007*\"healthcare\" + 0.006*\"right\" + 0.006*\"health\" + 0.006*\"care\" + 0.005*\"woman\" + 0.005*\"get\" + 0.005*\"amp\" + 0.004*\"affordable\" + 0.004*\"people\" + 0.004*\"insurance\"\n",
      "Topic: 1 \n",
      "Words: 0.008*\"healthcare\" + 0.007*\"care\" + 0.006*\"make\" + 0.006*\"amp\" + 0.006*\"health\" + 0.006*\"vote\" + 0.006*\"work\" + 0.005*\"support\" + 0.005*\"congress\" + 0.005*\"affordable\"\n",
      "Topic: 2 \n",
      "Words: 0.007*\"care\" + 0.007*\"health\" + 0.006*\"amp\" + 0.006*\"healthcare\" + 0.005*\"work\" + 0.005*\"american\" + 0.005*\"woman\" + 0.005*\"fight\" + 0.004*\"need\" + 0.004*\"vote\"\n",
      "Topic: 3 \n",
      "Words: 0.008*\"healthcare\" + 0.007*\"care\" + 0.006*\"health\" + 0.006*\"amp\" + 0.005*\"condition\" + 0.005*\"work\" + 0.005*\"family\" + 0.005*\"need\" + 0.005*\"support\" + 0.005*\"american\"\n",
      "Topic: 4 \n",
      "Words: 0.007*\"amp\" + 0.006*\"healthcare\" + 0.006*\"care\" + 0.006*\"health\" + 0.005*\"vote\" + 0.005*\"insurance\" + 0.004*\"need\" + 0.004*\"make\" + 0.004*\"everyone\" + 0.004*\"work\"\n",
      "Topic: 5 \n",
      "Words: 0.006*\"amp\" + 0.006*\"healthcare\" + 0.006*\"health\" + 0.005*\"care\" + 0.005*\"insurance\" + 0.005*\"work\" + 0.004*\"healthy\" + 0.004*\"people\" + 0.004*\"family\" + 0.004*\"support\"\n",
      "Topic: 6 \n",
      "Words: 0.007*\"care\" + 0.007*\"health\" + 0.007*\"amp\" + 0.007*\"healthcare\" + 0.006*\"need\" + 0.005*\"mental\" + 0.005*\"people\" + 0.005*\"access\" + 0.004*\"work\" + 0.004*\"community\"\n",
      "Topic: 7 \n",
      "Words: 0.008*\"care\" + 0.007*\"healthcare\" + 0.007*\"fight\" + 0.006*\"health\" + 0.006*\"access\" + 0.005*\"affordable\" + 0.005*\"right\" + 0.005*\"amp\" + 0.005*\"american\" + 0.005*\"need\"\n",
      "Topic: 8 \n",
      "Words: 0.007*\"amp\" + 0.007*\"care\" + 0.006*\"health\" + 0.006*\"healthcare\" + 0.005*\"condition\" + 0.005*\"protect\" + 0.005*\"people\" + 0.005*\"fight\" + 0.005*\"american\" + 0.005*\"need\"\n",
      "Topic: 9 \n",
      "Words: 0.008*\"amp\" + 0.006*\"healthcare\" + 0.006*\"need\" + 0.006*\"care\" + 0.006*\"health\" + 0.005*\"vote\" + 0.004*\"people\" + 0.004*\"year\" + 0.004*\"family\" + 0.004*\"program\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in house_lda_model_tfidf.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Democrat Cleaning Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dem_tweets_select = pd.DataFrame(db.read(data_query.format(\"democrat_select\")))\n",
    "dem_docs_select = [ast.literal_eval(doc) for doc in  dem_tweets_select[0].tolist()]\n",
    "dem_dict_select = corpora.Dictionary(dem_docs_select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Alter no_above to filter out frequently occuring words\n",
    "dem_dict_select.filter_extremes(no_below=15, no_above=1, keep_n=10000)\n",
    "dem_bow_corpus_select = [dem_dict_select.doc2bow(doc) for doc in dem_docs_select]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@realdonaldtrump, 1057 times\n",
      "vote, 977 times\n",
      "trump, 940 times\n",
      "amp, 915 times\n",
      "get, 730 times\n",
      "#theresistance, 602 times\n",
      "go, 587 times\n",
      "like, 545 times\n",
      "people, 505 times\n",
      "#maga, 494 times\n",
      "need, 469 times\n",
      "make, 443 times\n",
      "#votethemout, 421 times\n",
      "#trump, 418 times\n",
      "dont, 411 times\n",
      "say, 391 times\n",
      "time, 381 times\n",
      "follow, 381 times\n",
      "#fbr, 364 times\n",
      "know, 360 times\n",
      "one, 343 times\n",
      "want, 336 times\n",
      "take, 327 times\n",
      "let, 323 times\n",
      "right, 323 times\n",
      "#impeachtrump, 318 times\n",
      "back, 316 times\n",
      "good, 299 times\n",
      "america, 292 times\n",
      "think, 285 times\n",
      "democrat, 277 times\n",
      "would, 275 times\n",
      "im, 269 times\n",
      "@gop, 268 times\n",
      "see, 267 times\n",
      "come, 266 times\n",
      "#vote, 262 times\n",
      "country, 262 times\n",
      "please, 256 times\n",
      "day, 250 times\n",
      "republican, 245 times\n",
      "american, 239 times\n",
      "via, 237 times\n",
      "#trumprussia, 236 times\n",
      "party, 235 times\n",
      "work, 234 times\n",
      "must, 233 times\n",
      "help, 230 times\n",
      "election, 227 times\n",
      "support, 227 times\n"
     ]
    }
   ],
   "source": [
    "dem_counts_select = get_word_counts(dem_bow_corpus_select)\n",
    "print_word_counts(dem_counts_select, 50, dem_dict_select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dem_tfidf_select = models.TfidfModel(dem_bow_corpus_select)\n",
    "dem_corpus_tfidf_select = dem_tfidf_select[dem_bow_corpus_select]\n",
    "dem_lda_model = models.LdaMulticore(dem_bow_corpus_select, num_topics=10, id2word=dem_dict_select, passes=2, workers=2)\n",
    "dem_lda_model_tfidf = models.LdaMulticore(dem_corpus_tfidf_select, num_topics=10, id2word=dem_dict_select, passes=2, workers=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
