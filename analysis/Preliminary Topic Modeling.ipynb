{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary \"Base\" Topic Modeling\n",
    "Citation:\n",
    "https://towardsdatascience.com/topic-modeling-and-latent-dirichlet-allocation-in-python-9bf156893c24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils.db_client import DBClient\n",
    "import pandas as pd\n",
    "from gensim import corpora, models\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm trying\n",
      "Connected to political tweets DB\n"
     ]
    }
   ],
   "source": [
    "db = DBClient(secrets_path = \"../configs/db_secrets.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_query = \"\"\"\n",
    "with random_tweets as (\n",
    "    select tweet_text_clean, Random() from staging.{}\n",
    "    where tweet_date between '2018-01-01' and '2019-01-01'\n",
    "    order by Random()\n",
    "    limit 10000)\n",
    "select tweet_text_clean \n",
    "from random_tweets;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tax_query = \"\"\"\n",
    "select tweet_text_clean from staging.{}\n",
    "where tweet_date between '2018-01-01' and '2019-01-01'\n",
    "and tweet_text_clean like '%health%'\n",
    "limit 10000  \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_word_counts(bow_corpus):\n",
    "    counts = {}\n",
    "    for bow in bow_corpus:\n",
    "        for word in bow:\n",
    "            if word[0] not in counts.keys():\n",
    "                counts[word[0]] = 0\n",
    "            counts[word[0]] += word[1]\n",
    "    return [(k, counts[k]) for k in sorted(counts, key=counts.get, reverse=True)]\n",
    "\n",
    "def print_word_counts(word_counts, num_words, word_dict):\n",
    "    for tup in word_counts[0:num_words]:\n",
    "        print(f\"{word_dict[tup[0]]}, {tup[1]} times\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Democrats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dem_tax_tweets = pd.DataFrame(db.read(tax_query.format(\"democrat\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['omg', '#barbaric', 'amp', '#fiendish', '#cor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['@housedemocrats', '@gop', 'go', 'stop', 'pot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['@tedlieu', '@speakerryan', 'might', 'nice', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['#democraticagenda', 'affordable', 'healthcar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['@foxnews', '@gregabbotttx', 'stop', 'take', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>['@pelucachick46', '@tomperez', '@nancypelosi'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>['healthcare', 'immigration', 'tax', 'reform',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>['@realdonaldtrump', '@momsdemand', '@corapunz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>['@realdonaldtrump', 'hey', '#oh12', '#gotv', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>['im', 'sure', 'im', 'happy', 'result', 'study...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>['chuck', 'norris', 'approves', 'get', 'fit', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>['please', 'take', 'time', 'get', 'involved', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>['nasty', 'woman', 'earring', '#handmade', 'sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>['@cacountryman', '#rethinkalabama', '#neweraf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>['extremist', 'pick', 'scotus', 'could', 'pret...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>['@mamarose2017', '@keanothedog', '@troublingt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>['paycheck', '8181', 'month', '@gop', 'tax', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>['wake', 'call', 'think', 'vote', 'doesnt', 'm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>['rt', '#election2018', 'cd22', '#winblue', 's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>['@pajjr2016', '@bornabrit1', 'hell', 'see', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>['leave', 'another', 'evening', '@flipitblue',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>['new', '#healthcare', 'sabotage', 'trump', 'o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>['@aquilasuperbia', '@nutritionbee', '@eatheal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>['havent', 'voted', 'vote', 'danny', 'oconnor'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>['thank', 'everyone', 'march', 'calledpostcard...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>['body', 'never', 'compare', 'halfeaten', 'foo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>['mad', '@barackobama', 'didnt', 'sign', 'bill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>['big', 'thanks', '@coloradodems', 'endorsemen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>['@heyyou2486', 'hi', 'im', 'sorry', 'miss', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>['@kharyp', '#grabyourwallet', '@cvspharmacy',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>['#jeffflake', 'permanently', 'go', 'away', 'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>['florida', 'friend', 'family', 'gotv', 'yall'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>['@jamesmpope', '@cspanwj', '@mkazin', '@georg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>['thank', 'continued', 'support', 'amp', 'stro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>['resistance', 'need', 'rightwing', 'judge', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>['im', '#teampelosi', 'freshman', 'newbie', 'o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>['@markknoller', '@presssec', '@kellyannepolls...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>['#voteblue', 'say', 'yes', 'affordable', 'hea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>['worker', 'stage', '1day', 'protest', 'southe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>['yes', 'congrats', '@andykimnj', 'amp', '#nj0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>['keep', '#bluewave', 'go', 'write', '#postcar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>['@resetamer2018', '@gypsyinca', '@rosewoo1509...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>['#smartdissent', 'database', 'action', '#trum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>['add', 'name', 'dont', 'let', 'trump', 'steal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>['@cameronkgvi', '@sruhle', 'join', '#ivoted',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>['@mimiwaltersca', 'seeeing', 'smile', 'laugh'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>['@abc', 'republican', 'still', 'try', 'kill',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>['ironyhypocrisy', 'alert', 'ppl', 'crowdfundi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>['shame', 'anyone', 'tear', '#petedavidson', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>['mercury', 'emission', 'rollback', 'vengeful'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>['@wvjoe911', 'old', 'asshole', 'fl', 'worry',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>['@heaven526', '@individualone19', '#fbr', '#r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>['im', 'affordable', 'care', 'act', 'like', 'a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>['instead', 'bitch', '@nancypelosi', 'try', 'c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>['@outnumberedot', '@noellenikpour', '@realdoc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>['health', 'america', 'via', 'passle', '@axcoi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>['@gopchairwoman', '@hawleymo', '@realdonaldtr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>['vote', 'vote', 'vote', 'health', 'child', 'u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>['@gop', 'amp', '@realdonaldtrump', 'afraid', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>['#smartdissent', 'database', 'action', '#trum...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1006 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      0\n",
       "0     ['omg', '#barbaric', 'amp', '#fiendish', '#cor...\n",
       "1     ['@housedemocrats', '@gop', 'go', 'stop', 'pot...\n",
       "2     ['@tedlieu', '@speakerryan', 'might', 'nice', ...\n",
       "3     ['#democraticagenda', 'affordable', 'healthcar...\n",
       "4     ['@foxnews', '@gregabbotttx', 'stop', 'take', ...\n",
       "5     ['@pelucachick46', '@tomperez', '@nancypelosi'...\n",
       "6     ['healthcare', 'immigration', 'tax', 'reform',...\n",
       "7     ['@realdonaldtrump', '@momsdemand', '@corapunz...\n",
       "8     ['@realdonaldtrump', 'hey', '#oh12', '#gotv', ...\n",
       "9     ['im', 'sure', 'im', 'happy', 'result', 'study...\n",
       "10    ['chuck', 'norris', 'approves', 'get', 'fit', ...\n",
       "11    ['please', 'take', 'time', 'get', 'involved', ...\n",
       "12    ['nasty', 'woman', 'earring', '#handmade', 'sa...\n",
       "13    ['@cacountryman', '#rethinkalabama', '#neweraf...\n",
       "14    ['extremist', 'pick', 'scotus', 'could', 'pret...\n",
       "15    ['@mamarose2017', '@keanothedog', '@troublingt...\n",
       "16    ['paycheck', '8181', 'month', '@gop', 'tax', '...\n",
       "17    ['wake', 'call', 'think', 'vote', 'doesnt', 'm...\n",
       "18    ['rt', '#election2018', 'cd22', '#winblue', 's...\n",
       "19    ['@pajjr2016', '@bornabrit1', 'hell', 'see', '...\n",
       "20    ['leave', 'another', 'evening', '@flipitblue',...\n",
       "21    ['new', '#healthcare', 'sabotage', 'trump', 'o...\n",
       "22    ['@aquilasuperbia', '@nutritionbee', '@eatheal...\n",
       "23    ['havent', 'voted', 'vote', 'danny', 'oconnor'...\n",
       "24    ['thank', 'everyone', 'march', 'calledpostcard...\n",
       "25    ['body', 'never', 'compare', 'halfeaten', 'foo...\n",
       "26    ['mad', '@barackobama', 'didnt', 'sign', 'bill...\n",
       "27    ['big', 'thanks', '@coloradodems', 'endorsemen...\n",
       "28    ['@heyyou2486', 'hi', 'im', 'sorry', 'miss', '...\n",
       "29    ['@kharyp', '#grabyourwallet', '@cvspharmacy',...\n",
       "...                                                 ...\n",
       "976   ['#jeffflake', 'permanently', 'go', 'away', 'd...\n",
       "977   ['florida', 'friend', 'family', 'gotv', 'yall'...\n",
       "978   ['@jamesmpope', '@cspanwj', '@mkazin', '@georg...\n",
       "979   ['thank', 'continued', 'support', 'amp', 'stro...\n",
       "980   ['resistance', 'need', 'rightwing', 'judge', '...\n",
       "981   ['im', '#teampelosi', 'freshman', 'newbie', 'o...\n",
       "982   ['@markknoller', '@presssec', '@kellyannepolls...\n",
       "983   ['#voteblue', 'say', 'yes', 'affordable', 'hea...\n",
       "984   ['worker', 'stage', '1day', 'protest', 'southe...\n",
       "985   ['yes', 'congrats', '@andykimnj', 'amp', '#nj0...\n",
       "986   ['keep', '#bluewave', 'go', 'write', '#postcar...\n",
       "987   ['@resetamer2018', '@gypsyinca', '@rosewoo1509...\n",
       "988   ['#smartdissent', 'database', 'action', '#trum...\n",
       "989   ['add', 'name', 'dont', 'let', 'trump', 'steal...\n",
       "990   ['@cameronkgvi', '@sruhle', 'join', '#ivoted',...\n",
       "991   ['@mimiwaltersca', 'seeeing', 'smile', 'laugh'...\n",
       "992   ['@abc', 'republican', 'still', 'try', 'kill',...\n",
       "993   ['ironyhypocrisy', 'alert', 'ppl', 'crowdfundi...\n",
       "994   ['shame', 'anyone', 'tear', '#petedavidson', '...\n",
       "995   ['mercury', 'emission', 'rollback', 'vengeful'...\n",
       "996   ['@wvjoe911', 'old', 'asshole', 'fl', 'worry',...\n",
       "997   ['@heaven526', '@individualone19', '#fbr', '#r...\n",
       "998   ['im', 'affordable', 'care', 'act', 'like', 'a...\n",
       "999   ['instead', 'bitch', '@nancypelosi', 'try', 'c...\n",
       "1000  ['@outnumberedot', '@noellenikpour', '@realdoc...\n",
       "1001  ['health', 'america', 'via', 'passle', '@axcoi...\n",
       "1002  ['@gopchairwoman', '@hawleymo', '@realdonaldtr...\n",
       "1003  ['vote', 'vote', 'vote', 'health', 'child', 'u...\n",
       "1004  ['@gop', 'amp', '@realdonaldtrump', 'afraid', ...\n",
       "1005  ['#smartdissent', 'database', 'action', '#trum...\n",
       "\n",
       "[1006 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dem_tax_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dem_tweets = pd.DataFrame(db.read(tax_query.format(\"democrat\")))\n",
    "dem_docs = [ast.literal_eval(doc) for doc in  dem_tweets[0].tolist()]\n",
    "dem_dict = corpora.Dictionary(dem_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Alter no_above to filter out frequently occuring words\n",
    "dem_dict.filter_extremes(no_below=15, no_above=1, keep_n=10000)\n",
    "dem_bow_corpus = [dem_dict.doc2bow(doc) for doc in dem_docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top Word Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "healthcare, 355 times\n",
      "#voteblue, 310 times\n",
      "health, 283 times\n",
      "vote, 258 times\n",
      "amp, 256 times\n",
      "#resist, 248 times\n",
      "#healthcare, 202 times\n",
      "care, 183 times\n",
      "#bluewave, 172 times\n",
      "#democrats, 135 times\n",
      "take, 121 times\n",
      "#bluewave2018, 104 times\n",
      "right, 99 times\n",
      "need, 97 times\n",
      "get, 96 times\n",
      "#resistance, 94 times\n",
      "away, 85 times\n",
      "people, 84 times\n",
      "want, 83 times\n",
      "@realdonaldtrump, 81 times\n",
      "trump, 80 times\n",
      "like, 74 times\n",
      "dont, 73 times\n",
      "@gop, 72 times\n",
      "go, 69 times\n",
      "american, 66 times\n",
      "gop, 61 times\n",
      "#trump, 57 times\n",
      "condition, 56 times\n",
      "make, 55 times\n",
      "affordable, 54 times\n",
      "tax, 54 times\n",
      "pay, 54 times\n",
      "save, 53 times\n",
      "education, 51 times\n",
      "issue, 50 times\n",
      "#maga, 49 times\n",
      "support, 49 times\n",
      "woman, 49 times\n",
      "republican, 49 times\n",
      "#vote, 48 times\n",
      "security, 48 times\n",
      "social, 48 times\n",
      "time, 46 times\n",
      "good, 46 times\n",
      "lie, 46 times\n",
      "#gop, 43 times\n",
      "let, 43 times\n",
      "child, 43 times\n",
      "work, 42 times\n"
     ]
    }
   ],
   "source": [
    "dem_counts = get_word_counts(dem_bow_corpus)\n",
    "print_word_counts(dem_counts, 50, dem_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dem_tfidf = models.TfidfModel(dem_bow_corpus)\n",
    "dem_corpus_tfidf = dem_tfidf[dem_bow_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dem_lda_model = models.LdaMulticore(dem_bow_corpus, num_topics=10, id2word=dem_dict, passes=2, workers=2)\n",
    "dem_lda_model_tfidf = models.LdaMulticore(dem_corpus_tfidf, num_topics=10, id2word=dem_dict, passes=2, workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.086*\"care\" + 0.053*\"right\" + 0.045*\"health\" + 0.043*\"#vote\" + 0.037*\"#bluewave\" + 0.037*\"#voteblue\" + 0.034*\"#healthcare\" + 0.025*\"amp\" + 0.024*\"issue\" + 0.023*\"vote\"\n",
      "Topic: 1 \n",
      "Words: 0.086*\"#voteblue\" + 0.068*\"healthcare\" + 0.034*\"tax\" + 0.032*\"#resist\" + 0.029*\"vote\" + 0.021*\"amp\" + 0.020*\"medicare\" + 0.019*\"health\" + 0.018*\"@gop\" + 0.017*\"let\"\n",
      "Topic: 2 \n",
      "Words: 0.085*\"healthcare\" + 0.058*\"#voteblue\" + 0.040*\"vote\" + 0.022*\"health\" + 0.020*\"#healthcare\" + 0.020*\"gop\" + 0.020*\"#resist\" + 0.018*\"get\" + 0.018*\"take\" + 0.018*\"care\"\n",
      "Topic: 3 \n",
      "Words: 0.067*\"amp\" + 0.066*\"#bluewave\" + 0.065*\"#healthcare\" + 0.027*\"#trump\" + 0.023*\"#womensrights\" + 0.023*\"#democrats\" + 0.023*\"#education\" + 0.023*\"stay\" + 0.022*\"#environment\" + 0.022*\"@gop\"\n",
      "Topic: 4 \n",
      "Words: 0.068*\"health\" + 0.038*\"amp\" + 0.035*\"take\" + 0.030*\"care\" + 0.027*\"#democrats\" + 0.026*\"away\" + 0.024*\"healthcare\" + 0.023*\"#bluewave\" + 0.022*\"#voteblue\" + 0.021*\"child\"\n",
      "Topic: 5 \n",
      "Words: 0.054*\"amp\" + 0.047*\"healthcare\" + 0.026*\"dont\" + 0.024*\"#voteblue\" + 0.023*\"#resist\" + 0.022*\"#healthcare\" + 0.021*\"security\" + 0.020*\"social\" + 0.019*\"#bluewave\" + 0.018*\"get\"\n",
      "Topic: 6 \n",
      "Words: 0.064*\"amp\" + 0.048*\"health\" + 0.040*\"#resist\" + 0.032*\"#democrats\" + 0.025*\"care\" + 0.023*\"#healthcare\" + 0.020*\"take\" + 0.020*\"issue\" + 0.020*\"#gop\" + 0.018*\"#veterans\"\n",
      "Topic: 7 \n",
      "Words: 0.077*\"#resist\" + 0.043*\"#voteblue\" + 0.034*\"#bluewave\" + 0.033*\"#healthcare\" + 0.030*\"healthcare\" + 0.027*\"people\" + 0.026*\"#trump\" + 0.022*\"health\" + 0.022*\"#votebluetosaveamerica\" + 0.018*\"well\"\n",
      "Topic: 8 \n",
      "Words: 0.072*\"need\" + 0.054*\"#resist\" + 0.036*\"healthcare\" + 0.034*\"#voteblue\" + 0.032*\"#bluewave2018\" + 0.032*\"take\" + 0.030*\"care\" + 0.029*\"health\" + 0.025*\"vote\" + 0.024*\"#resistance\"\n",
      "Topic: 9 \n",
      "Words: 0.095*\"vote\" + 0.053*\"health\" + 0.040*\"healthcare\" + 0.038*\"right\" + 0.030*\"care\" + 0.029*\"#voteblue\" + 0.023*\"like\" + 0.021*\"#democrats\" + 0.020*\"affordable\" + 0.016*\"#resist\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in dem_lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.038*\"healthcare\" + 0.022*\"#voteblue\" + 0.022*\"take\" + 0.022*\"want\" + 0.021*\"must\" + 0.021*\"#bluewave2018\" + 0.020*\"away\" + 0.020*\"#resist\" + 0.018*\"health\" + 0.016*\"trump\"\n",
      "Topic: 1 \n",
      "Words: 0.045*\"#bluewave2018\" + 0.031*\"#votebluetosaveamerica\" + 0.030*\"#bluewave\" + 0.025*\"#resistance\" + 0.020*\"amp\" + 0.019*\"know\" + 0.019*\"child\" + 0.018*\"people\" + 0.016*\"strong\" + 0.016*\"use\"\n",
      "Topic: 2 \n",
      "Words: 0.043*\"vote\" + 0.023*\"right\" + 0.023*\"amp\" + 0.023*\"#vote\" + 0.022*\"#resistance\" + 0.021*\"get\" + 0.021*\"#resist\" + 0.020*\"trump\" + 0.018*\"health\" + 0.018*\"good\"\n",
      "Topic: 3 \n",
      "Words: 0.022*\"#womenshealth\" + 0.022*\"#healthcare\" + 0.021*\"health\" + 0.020*\"gun\" + 0.019*\"vote\" + 0.018*\"#gop\" + 0.018*\"#democrats\" + 0.018*\"public\" + 0.016*\"issue\" + 0.016*\"#voteblue\"\n",
      "Topic: 4 \n",
      "Words: 0.025*\"lie\" + 0.025*\"#voteblue\" + 0.024*\"#resist\" + 0.024*\"care\" + 0.022*\"access\" + 0.022*\"need\" + 0.021*\"vote\" + 0.021*\"health\" + 0.020*\"cut\" + 0.020*\"go\"\n",
      "Topic: 5 \n",
      "Words: 0.045*\"#healthcare\" + 0.029*\"#democrats\" + 0.023*\"#voteblue\" + 0.021*\"#resist\" + 0.020*\"vote\" + 0.019*\"health\" + 0.017*\"healthcare\" + 0.017*\"coverage\" + 0.017*\"#bluewave\" + 0.017*\"come\"\n",
      "Topic: 6 \n",
      "Words: 0.027*\"#healthcarevoter\" + 0.022*\"#bluewave\" + 0.019*\"amp\" + 0.018*\"say\" + 0.017*\"like\" + 0.017*\"health\" + 0.015*\"care\" + 0.014*\"#smartdissent\" + 0.014*\"#healthcare\" + 0.014*\"universal\"\n",
      "Topic: 7 \n",
      "Words: 0.031*\"#voteblue\" + 0.024*\"#resistance\" + 0.023*\"amp\" + 0.021*\"#impeachtrump\" + 0.021*\"care\" + 0.020*\"save\" + 0.019*\"lie\" + 0.018*\"#healthcare\" + 0.016*\"healthcare\" + 0.015*\"#bluewave\"\n",
      "Topic: 8 \n",
      "Words: 0.052*\"#resist\" + 0.046*\"#health\" + 0.029*\"#foxnews\" + 0.028*\"#maga\" + 0.022*\"get\" + 0.021*\"#trump\" + 0.020*\"#resistance\" + 0.019*\"@realdonaldtrump\" + 0.018*\"#veterans\" + 0.015*\"healthcare\"\n",
      "Topic: 9 \n",
      "Words: 0.022*\"#voteblue\" + 0.021*\"#metoo\" + 0.021*\"#voteblue2018\" + 0.020*\"end\" + 0.019*\"let\" + 0.018*\"healthcare\" + 0.017*\"security\" + 0.017*\"take\" + 0.016*\"republican\" + 0.016*\"#democrats\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in dem_lda_model_tfidf.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Republicans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rep_tweets = pd.DataFrame(db.read(tax_query.format(\"republican\")))\n",
    "rep_docs = [ast.literal_eval(doc) for doc in  rep_tweets[0].tolist()]\n",
    "rep_dict = corpora.Dictionary(rep_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adjust no_above to filter frequently occuring words\n",
    "rep_dict.filter_extremes(no_below=15, no_above=1, keep_n=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rep_bow_corpus = [rep_dict.doc2bow(doc) for doc in rep_docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top Word Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#maga, 277 times\n",
      "health, 243 times\n",
      "#trump, 201 times\n",
      "healthcare, 129 times\n",
      "#gop, 118 times\n",
      "#healthcare, 104 times\n",
      "care, 85 times\n",
      "@realdonaldtrump, 84 times\n",
      "trump, 68 times\n",
      "mental, 67 times\n",
      "get, 59 times\n",
      "people, 58 times\n",
      "make, 56 times\n",
      "dont, 53 times\n",
      "need, 52 times\n",
      "vote, 47 times\n",
      "want, 45 times\n",
      "tax, 45 times\n",
      "take, 44 times\n",
      "go, 42 times\n",
      "gun, 40 times\n",
      "#health, 39 times\n",
      "follow, 38 times\n",
      "insurance, 38 times\n",
      "give, 37 times\n",
      "right, 36 times\n",
      "like, 36 times\n",
      "america, 35 times\n",
      "back, 34 times\n",
      "good, 34 times\n",
      "cut, 33 times\n",
      "pay, 33 times\n",
      "issue, 32 times\n",
      "say, 32 times\n",
      "would, 32 times\n",
      "@gop, 30 times\n",
      "@potus, 29 times\n",
      "healthy, 29 times\n",
      "american, 29 times\n",
      "child, 28 times\n",
      "one, 28 times\n",
      "let, 28 times\n",
      "please, 27 times\n",
      "school, 27 times\n",
      "know, 27 times\n",
      "president, 26 times\n",
      "work, 26 times\n",
      "country, 25 times\n",
      "talk, 24 times\n",
      "stop, 24 times\n"
     ]
    }
   ],
   "source": [
    "rep_counts = get_word_counts(rep_bow_corpus)\n",
    "print_word_counts(rep_counts, 50, rep_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rep_tfidf = models.TfidfModel(rep_bow_corpus)\n",
    "rep_corpus_tfidf = rep_tfidf[rep_bow_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rep_lda_model = models.LdaMulticore(rep_bow_corpus, num_topics=10, id2word=rep_dict, passes=2, workers=2)\n",
    "rep_lda_model_tfidf = models.LdaMulticore(rep_corpus_tfidf, num_topics=10, id2word=rep_dict, passes=2, workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.219*\"#maga\" + 0.083*\"health\" + 0.036*\"follow\" + 0.030*\"mental\" + 0.023*\"get\" + 0.023*\"back\" + 0.022*\"gun\" + 0.022*\"thanks\" + 0.022*\"@realdonaldtrump\" + 0.021*\"school\"\n",
      "Topic: 1 \n",
      "Words: 0.119*\"health\" + 0.061*\"#trump\" + 0.057*\"need\" + 0.047*\"#gop\" + 0.046*\"insurance\" + 0.040*\"@realdonaldtrump\" + 0.036*\"#maga\" + 0.032*\"go\" + 0.028*\"people\" + 0.026*\"care\"\n",
      "Topic: 2 \n",
      "Words: 0.079*\"healthcare\" + 0.055*\"health\" + 0.045*\"child\" + 0.040*\"vote\" + 0.039*\"#maga\" + 0.037*\"good\" + 0.033*\"#gop\" + 0.031*\"one\" + 0.029*\"@gop\" + 0.026*\"dont\"\n",
      "Topic: 3 \n",
      "Words: 0.155*\"#trump\" + 0.118*\"#healthcare\" + 0.049*\"#gop\" + 0.040*\"action\" + 0.036*\"#environment\" + 0.028*\"@gop\" + 0.024*\"#health\" + 0.022*\"healthcare\" + 0.021*\"vote\" + 0.021*\"make\"\n",
      "Topic: 4 \n",
      "Words: 0.094*\"#trump\" + 0.066*\"#healthcare\" + 0.064*\"try\" + 0.059*\"get\" + 0.048*\"people\" + 0.047*\"go\" + 0.043*\"take\" + 0.041*\"cut\" + 0.035*\"healthcare\" + 0.034*\"let\"\n",
      "Topic: 5 \n",
      "Words: 0.096*\"health\" + 0.087*\"#gop\" + 0.077*\"mental\" + 0.060*\"#trump\" + 0.045*\"trump\" + 0.043*\"#healthcare\" + 0.038*\"gun\" + 0.035*\"say\" + 0.029*\"america\" + 0.029*\"plan\"\n",
      "Topic: 6 \n",
      "Words: 0.086*\"healthcare\" + 0.065*\"want\" + 0.054*\"dont\" + 0.045*\"#gop\" + 0.040*\"tax\" + 0.036*\"#trump\" + 0.026*\"make\" + 0.023*\"@potus\" + 0.022*\"go\" + 0.022*\"cut\"\n",
      "Topic: 7 \n",
      "Words: 0.099*\"#trump\" + 0.097*\"#maga\" + 0.068*\"health\" + 0.051*\"make\" + 0.037*\"trump\" + 0.033*\"#health\" + 0.032*\"#healthcare\" + 0.027*\"healthcare\" + 0.027*\"#gop\" + 0.025*\"healthy\"\n",
      "Topic: 8 \n",
      "Words: 0.086*\"#maga\" + 0.049*\"health\" + 0.040*\"trump\" + 0.040*\"#trump\" + 0.039*\"healthcare\" + 0.039*\"would\" + 0.034*\"know\" + 0.032*\"care\" + 0.031*\"get\" + 0.025*\"let\"\n",
      "Topic: 9 \n",
      "Words: 0.089*\"#maga\" + 0.072*\"health\" + 0.058*\"care\" + 0.054*\"@realdonaldtrump\" + 0.047*\"like\" + 0.031*\"healthcare\" + 0.031*\"people\" + 0.029*\"vote\" + 0.028*\"job\" + 0.025*\"follow\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in rep_lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.075*\"#mentalhealth\" + 0.058*\"#trump\" + 0.047*\"want\" + 0.042*\"gun\" + 0.038*\"health\" + 0.038*\"one\" + 0.029*\"school\" + 0.025*\"#gop\" + 0.025*\"mental\" + 0.024*\"follow\"\n",
      "Topic: 1 \n",
      "Words: 0.051*\"insurance\" + 0.050*\"need\" + 0.039*\"try\" + 0.035*\"right\" + 0.033*\"make\" + 0.031*\"people\" + 0.031*\"#trump\" + 0.030*\"health\" + 0.030*\"@realdonaldtrump\" + 0.029*\"healthy\"\n",
      "Topic: 2 \n",
      "Words: 0.038*\"back\" + 0.036*\"make\" + 0.036*\"#maga\" + 0.028*\"keep\" + 0.027*\"health\" + 0.026*\"need\" + 0.026*\"america\" + 0.024*\"see\" + 0.024*\"great\" + 0.024*\"@realdonaldtrump\"\n",
      "Topic: 3 \n",
      "Words: 0.077*\"#healthcare\" + 0.051*\"#trump\" + 0.041*\"#gop\" + 0.038*\"would\" + 0.037*\"#maga\" + 0.033*\"issue\" + 0.033*\"vote\" + 0.032*\"please\" + 0.029*\"follow\" + 0.027*\"people\"\n",
      "Topic: 4 \n",
      "Words: 0.055*\"get\" + 0.054*\"every\" + 0.049*\"healthcare\" + 0.039*\"like\" + 0.039*\"even\" + 0.036*\"life\" + 0.032*\"#maga\" + 0.029*\"say\" + 0.027*\"stop\" + 0.027*\"insurance\"\n",
      "Topic: 5 \n",
      "Words: 0.121*\"#maga\" + 0.101*\"health\" + 0.060*\"mental\" + 0.047*\"#trump\" + 0.041*\"@potus\" + 0.039*\"#tcot\" + 0.035*\"think\" + 0.028*\"trump\" + 0.028*\"#usa\" + 0.028*\"#potus\"\n",
      "Topic: 6 \n",
      "Words: 0.048*\"#trump\" + 0.044*\"take\" + 0.040*\"#environment\" + 0.040*\"free\" + 0.033*\"#health\" + 0.031*\"child\" + 0.030*\"away\" + 0.029*\"via\" + 0.029*\"care\" + 0.027*\"health\"\n",
      "Topic: 7 \n",
      "Words: 0.062*\"cut\" + 0.056*\"trump\" + 0.043*\"say\" + 0.041*\"bill\" + 0.033*\"health\" + 0.029*\"#gop\" + 0.028*\"go\" + 0.028*\"#trump\" + 0.026*\"president\" + 0.026*\"take\"\n",
      "Topic: 8 \n",
      "Words: 0.144*\"#health\" + 0.052*\"#trump\" + 0.038*\"#gop\" + 0.033*\"long\" + 0.032*\"healthcare\" + 0.027*\"#potus\" + 0.027*\"job\" + 0.026*\"order\" + 0.025*\"care\" + 0.024*\"cant\"\n",
      "Topic: 9 \n",
      "Words: 0.087*\"thanks\" + 0.068*\"healthcare\" + 0.039*\"america\" + 0.035*\"#gop\" + 0.035*\"#maga\" + 0.032*\"tax\" + 0.032*\"#usa\" + 0.031*\"give\" + 0.031*\"mental\" + 0.029*\"country\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in rep_lda_model_tfidf.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# House"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "house_tweets = pd.DataFrame(db.read(tax_query.format(\"house\")))\n",
    "house_docs = [ast.literal_eval(doc) for doc in  house_tweets[0].tolist()]\n",
    "house_dict = corpora.Dictionary(house_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "house_dict.filter_extremes(no_below=15, no_above=1, keep_n=10000)\n",
    "house_bow_corpus = [house_dict.doc2bow(doc) for doc in house_docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top Word Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "health, 5470 times\n",
      "healthcare, 3821 times\n",
      "care, 3043 times\n",
      "amp, 2365 times\n",
      "need, 1363 times\n",
      "people, 1330 times\n",
      "work, 1228 times\n",
      "fight, 1154 times\n",
      "american, 1122 times\n",
      "affordable, 1106 times\n",
      "make, 1086 times\n",
      "vote, 1073 times\n",
      "family, 1045 times\n",
      "access, 997 times\n",
      "right, 867 times\n",
      "congress, 863 times\n",
      "insurance, 827 times\n",
      "get, 819 times\n",
      "woman, 797 times\n",
      "support, 794 times\n",
      "protect, 794 times\n",
      "im, 755 times\n",
      "today, 715 times\n",
      "condition, 708 times\n",
      "take, 698 times\n",
      "community, 681 times\n",
      "cost, 675 times\n",
      "time, 653 times\n",
      "help, 645 times\n",
      "public, 618 times\n",
      "year, 608 times\n",
      "good, 601 times\n",
      "education, 596 times\n",
      "healthy, 587 times\n",
      "million, 584 times\n",
      "issue, 578 times\n",
      "must, 567 times\n",
      "coverage, 551 times\n",
      "system, 548 times\n",
      "one, 547 times\n",
      "like, 545 times\n",
      "trump, 543 times\n",
      "plan, 532 times\n",
      "job, 532 times\n",
      "new, 520 times\n",
      "quality, 513 times\n",
      "would, 502 times\n",
      "want, 490 times\n",
      "mental, 474 times\n",
      "tax, 472 times\n"
     ]
    }
   ],
   "source": [
    "house_counts = get_word_counts(house_bow_corpus)\n",
    "print_word_counts(house_counts, 50, house_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "house_tfidf = models.TfidfModel(house_bow_corpus)\n",
    "house_corpus_tfidf = house_tfidf[house_bow_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "house_lda_model = models.LdaMulticore(house_bow_corpus, num_topics=10, id2word=house_dict, passes=2, workers=2)\n",
    "house_lda_model_tfidf = models.LdaMulticore(house_corpus_tfidf, num_topics=10, id2word=house_dict, passes=2, workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.043*\"healthcare\" + 0.013*\"people\" + 0.012*\"amp\" + 0.012*\"health\" + 0.010*\"run\" + 0.009*\"congress\" + 0.009*\"security\" + 0.009*\"support\" + 0.009*\"great\" + 0.008*\"community\"\n",
      "Topic: 1 \n",
      "Words: 0.031*\"healthcare\" + 0.025*\"health\" + 0.013*\"amp\" + 0.012*\"today\" + 0.010*\"year\" + 0.010*\"community\" + 0.009*\"work\" + 0.009*\"healthy\" + 0.009*\"need\" + 0.008*\"gun\"\n",
      "Topic: 2 \n",
      "Words: 0.034*\"health\" + 0.027*\"amp\" + 0.024*\"care\" + 0.023*\"right\" + 0.018*\"woman\" + 0.017*\"healthcare\" + 0.014*\"vote\" + 0.010*\"get\" + 0.009*\"make\" + 0.008*\"today\"\n",
      "Topic: 3 \n",
      "Words: 0.044*\"health\" + 0.025*\"amp\" + 0.012*\"healthcare\" + 0.012*\"care\" + 0.011*\"public\" + 0.011*\"work\" + 0.010*\"community\" + 0.009*\"need\" + 0.009*\"family\" + 0.008*\"support\"\n",
      "Topic: 4 \n",
      "Words: 0.039*\"healthcare\" + 0.022*\"health\" + 0.020*\"access\" + 0.019*\"affordable\" + 0.017*\"need\" + 0.015*\"fight\" + 0.015*\"care\" + 0.014*\"amp\" + 0.013*\"family\" + 0.011*\"work\"\n",
      "Topic: 5 \n",
      "Words: 0.029*\"healthcare\" + 0.028*\"health\" + 0.015*\"work\" + 0.012*\"american\" + 0.012*\"people\" + 0.012*\"support\" + 0.011*\"time\" + 0.010*\"care\" + 0.010*\"system\" + 0.009*\"amp\"\n",
      "Topic: 6 \n",
      "Words: 0.054*\"health\" + 0.033*\"care\" + 0.017*\"amp\" + 0.016*\"condition\" + 0.013*\"trump\" + 0.011*\"people\" + 0.011*\"american\" + 0.010*\"need\" + 0.010*\"insurance\" + 0.010*\"coverage\"\n",
      "Topic: 7 \n",
      "Words: 0.040*\"healthcare\" + 0.025*\"vote\" + 0.018*\"health\" + 0.013*\"fight\" + 0.012*\"people\" + 0.012*\"amp\" + 0.010*\"need\" + 0.009*\"protect\" + 0.008*\"care\" + 0.008*\"right\"\n",
      "Topic: 8 \n",
      "Words: 0.024*\"healthcare\" + 0.021*\"health\" + 0.016*\"make\" + 0.012*\"cost\" + 0.012*\"insurance\" + 0.011*\"care\" + 0.011*\"drug\" + 0.011*\"people\" + 0.010*\"today\" + 0.010*\"american\"\n",
      "Topic: 9 \n",
      "Words: 0.064*\"health\" + 0.053*\"care\" + 0.010*\"healthcare\" + 0.010*\"affordable\" + 0.010*\"need\" + 0.009*\"woman\" + 0.008*\"people\" + 0.008*\"insurance\" + 0.008*\"access\" + 0.007*\"family\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in house_lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.007*\"healthcare\" + 0.007*\"amp\" + 0.006*\"care\" + 0.006*\"health\" + 0.006*\"condition\" + 0.005*\"community\" + 0.005*\"people\" + 0.005*\"need\" + 0.004*\"million\" + 0.004*\"american\"\n",
      "Topic: 1 \n",
      "Words: 0.007*\"care\" + 0.007*\"healthcare\" + 0.006*\"health\" + 0.005*\"amp\" + 0.005*\"need\" + 0.005*\"insurance\" + 0.005*\"coverage\" + 0.005*\"work\" + 0.005*\"plan\" + 0.004*\"get\"\n",
      "Topic: 2 \n",
      "Words: 0.008*\"amp\" + 0.006*\"healthcare\" + 0.006*\"care\" + 0.006*\"health\" + 0.006*\"fight\" + 0.005*\"family\" + 0.005*\"work\" + 0.005*\"need\" + 0.005*\"issue\" + 0.004*\"education\"\n",
      "Topic: 3 \n",
      "Words: 0.008*\"healthcare\" + 0.007*\"care\" + 0.007*\"amp\" + 0.006*\"health\" + 0.006*\"vote\" + 0.005*\"need\" + 0.005*\"access\" + 0.004*\"affordable\" + 0.004*\"right\" + 0.004*\"fight\"\n",
      "Topic: 4 \n",
      "Words: 0.007*\"healthcare\" + 0.006*\"care\" + 0.006*\"health\" + 0.006*\"amp\" + 0.006*\"affordable\" + 0.005*\"work\" + 0.005*\"insurance\" + 0.005*\"system\" + 0.005*\"thank\" + 0.004*\"fight\"\n",
      "Topic: 5 \n",
      "Words: 0.007*\"healthcare\" + 0.007*\"care\" + 0.006*\"health\" + 0.006*\"amp\" + 0.006*\"vote\" + 0.005*\"people\" + 0.005*\"time\" + 0.005*\"american\" + 0.005*\"country\" + 0.005*\"insurance\"\n",
      "Topic: 6 \n",
      "Words: 0.007*\"healthcare\" + 0.007*\"care\" + 0.006*\"amp\" + 0.006*\"health\" + 0.006*\"affordable\" + 0.005*\"access\" + 0.005*\"work\" + 0.005*\"need\" + 0.005*\"new\" + 0.005*\"veteran\"\n",
      "Topic: 7 \n",
      "Words: 0.008*\"amp\" + 0.007*\"need\" + 0.007*\"health\" + 0.006*\"care\" + 0.006*\"healthcare\" + 0.005*\"vote\" + 0.005*\"right\" + 0.005*\"congress\" + 0.005*\"make\" + 0.005*\"woman\"\n",
      "Topic: 8 \n",
      "Words: 0.007*\"care\" + 0.006*\"health\" + 0.006*\"healthcare\" + 0.006*\"amp\" + 0.005*\"family\" + 0.005*\"fight\" + 0.005*\"cost\" + 0.004*\"woman\" + 0.004*\"people\" + 0.004*\"access\"\n",
      "Topic: 9 \n",
      "Words: 0.008*\"right\" + 0.007*\"care\" + 0.007*\"healthcare\" + 0.006*\"amp\" + 0.006*\"american\" + 0.006*\"health\" + 0.006*\"woman\" + 0.006*\"fight\" + 0.005*\"people\" + 0.005*\"support\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in house_lda_model_tfidf.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Democrat Cleaning Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dem_tweets_select = pd.DataFrame(db.read(data_query.format(\"democrat_select\")))\n",
    "dem_docs_select = [ast.literal_eval(doc) for doc in  dem_tweets_select[0].tolist()]\n",
    "dem_dict_select = corpora.Dictionary(dem_docs_select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Alter no_above to filter out frequently occuring words\n",
    "dem_dict_select.filter_extremes(no_below=15, no_above=1, keep_n=10000)\n",
    "dem_bow_corpus_select = [dem_dict_select.doc2bow(doc) for doc in dem_docs_select]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vote, 1020 times\n",
      "@realdonaldtrump, 940 times\n",
      "trump, 935 times\n",
      "amp, 907 times\n",
      "get, 744 times\n",
      "go, 556 times\n",
      "#theresistance, 556 times\n",
      "like, 524 times\n",
      "people, 512 times\n",
      "#maga, 484 times\n",
      "dont, 480 times\n",
      "make, 464 times\n",
      "need, 454 times\n",
      "say, 394 times\n",
      "follow, 387 times\n",
      "#trump, 373 times\n",
      "time, 371 times\n",
      "#votethemout, 368 times\n",
      "take, 362 times\n",
      "know, 360 times\n",
      "one, 355 times\n",
      "want, 347 times\n",
      "let, 335 times\n",
      "#fbr, 310 times\n",
      "right, 305 times\n",
      "please, 297 times\n",
      "see, 296 times\n",
      "#impeachtrump, 293 times\n",
      "good, 289 times\n",
      "come, 287 times\n",
      "day, 284 times\n",
      "back, 278 times\n",
      "democrat, 277 times\n",
      "america, 273 times\n",
      "republican, 272 times\n",
      "@gop, 262 times\n",
      "im, 261 times\n",
      "would, 252 times\n",
      "think, 250 times\n",
      "work, 250 times\n",
      "country, 239 times\n",
      "american, 238 times\n",
      "#vote, 235 times\n",
      "must, 234 times\n",
      "election, 233 times\n",
      "president, 228 times\n",
      "lie, 227 times\n",
      "via, 221 times\n",
      "party, 220 times\n",
      "gop, 217 times\n"
     ]
    }
   ],
   "source": [
    "dem_counts_select = get_word_counts(dem_bow_corpus_select)\n",
    "print_word_counts(dem_counts_select, 50, dem_dict_select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dem_tfidf_select = models.TfidfModel(dem_bow_corpus_select)\n",
    "dem_corpus_tfidf_select = dem_tfidf_select[dem_bow_corpus_select]\n",
    "dem_lda_model = models.LdaMulticore(dem_bow_corpus_select, num_topics=10, id2word=dem_dict_select, passes=2, workers=2)\n",
    "dem_lda_model_tfidf = models.LdaMulticore(dem_corpus_tfidf_select, num_topics=10, id2word=dem_dict_select, passes=2, workers=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
